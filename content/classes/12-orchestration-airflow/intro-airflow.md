# Airflow

J√° exploramos o conceito de orquestra√ß√£o e como o **Prefect** nos ajuda a automatizar e gerenciar *pipelines* de dados.

Agora, vamos explorar uma das ferramentas mais populares para orquestra√ß√£o em Engenharia de Dados: o **Apache Airflow**.

## O que √© o Airflow?

O **Apache Airflow** √© uma plataforma de c√≥digo aberto para desenvolver, agendar e monitorar *workflows* de dados de forma program√°tica. Originalmente criado pelo **Airbnb** em 2014, o **Airflow** tornou-se um projeto da **Apache Software Foundation** e hoje √© amplamente adotado pela ind√∫stria.

!!! tip "Airflow"
    Enquanto o **Prefect** √© uma ferramenta mais recente, o **Airflow** √© uma ferramenta j√° consolidada e amplamente usada na ind√∫stria, com uma comunidade grande e ativa.

## Principais Conceitos

Uma das ideias centrais do **Airflow** √© tratar fluxos de trabalho como c√≥digo. Isso √© conhecido como *Workflows as Code*.

!!! tip "Workflows as Code"
    Semelhante ao conceito de **Infraestrutura como C√≥digo (IaC)**, temos o conceito de **Workflows as Code**. Isso possibilita:

    *   **Versionamento:** Se o seu fluxo de trabalho √© c√≥digo, voc√™ pode usar `git` para controlar suas vers√µes.
    *   **Colabora√ß√£o:** Equipes de engenheiros de dados podem trabalhar juntas em um mesmo fluxo de trabalho.
    *   **Reutiliza√ß√£o:** Se voc√™ tem uma tarefa que se repete em v√°rios fluxos, c√≥digo pode ajudar.
    *   **Testes:** √â poss√≠vel testar fluxos de trabalho (testes unit√°rios).

Al√©m disso, o **Airflow** possui uma arquitetura robusta que o tornam flex√≠vel e escal√°vel, sendo os principais conceitos:

### DAGs (Directed Acyclic Graphs)

Seguimos com a mesma defini√ß√£o de **DAG** que vimos no **Prefect**.

Um **DAG** (Grafo Ac√≠clico Dirigido, do ingl√™s *Directed Acyclic Graph*) √© uma cole√ß√£o de todas as tarefas que voc√™ deseja executar em um *workflow*, organizadas de uma forma que reflete suas rela√ß√µes e depend√™ncias.

??? "DAG"
    Um **DAG** √© composto por:

    -   **Tarefas (*Tasks*):** S√£o as etapas individuais do seu fluxo de trabalho. Cada tarefa √© uma inst√¢ncia de um *Operador*. Por exemplo, uma tarefa pode ser executar um *script* **Python**, rodar uma query **SQL** ou transferir um arquivo.
    -   **Depend√™ncias (*Dependencies*):** As setas no grafo que definem a ordem em que as tarefas devem ser executadas. Por exemplo, a "tarefa C" s√≥ pode come√ßar depois que as "tarefas A" e "B" forem conclu√≠das com sucesso.
    -   **Ac√≠clico:** O fluxo de trabalho tem um in√≠cio e um fim claros, sem loops!

![Exemplo de DAG](dags.png)
**Fonte**: Documenta√ß√£o Oficial do Airflow

### Operadores (Operators)

Operadores s√£o os blocos de constru√ß√£o de um DAG. Eles s√£o templates pr√©-definidos para tarefas.

!!! tip "Operadores"
    O **Airflow** vem com uma biblioteca de operadores prontos para uso, e voc√™ pode criar os seus.

Alguns exemplos comuns:

-   `BashOperator`: Executa um comando **bash**.
-   `PythonOperator`: Executa uma fun√ß√£o **Python**.
-   `PostgresOperator`: Executa uma *query* em um banco de dados **PostgreSQL**.
-   `HttpOperator`: Envia uma requisi√ß√£o **HTTP**.
-   `DockerOperator`: Executa um comando dentro de um container **Docker**.

!!! info "Prefect vs. Airflow"

    No **Prefect**, voc√™ define suas tarefas usando a anota√ß√£o `@task` em fun√ß√µes Python e as organiza em um `@flow`.

    No **Airflow**, a estrutura √© um pouco mais expl√≠cita:

    -   Um **DAG** √© an√°logo a um `@flow` no Prefect. Ele define o fluxo de trabalho como um todo.
    -   Uma **Tarefa (Task)**, que √© uma inst√¢ncia de um **Operador**, √© an√°loga a uma `@task` no Prefect. Ela representa uma unidade de trabalho.

    A principal diferen√ßa conceitual √© que o Airflow for√ßa voc√™ a pensar em termos de **DAGs** e **Operadores** desde o in√≠cio, enquanto o **Prefect** abstrai parte dessa complexidade.

## Arquitetura do Airflow

O Airflow opera com v√°rios componentes principais:

1.  **Web Server:** Fornece a interface de usu√°rio (UI) onde voc√™ pode monitorar o status dos seus **DAGs**, visualizar logs e gerenciar seu ambiente.
2.  **Scheduler (Agendador):** √â o c√©rebro do Airflow. Ele monitora seus **DAGs**, verifica as depend√™ncias das tarefas e decide o que precisa ser executado e quando.
3.  **Executor:** √â o mecanismo que de fato executa as tarefas. O **Airflow** suporta diferentes tipos de executores, desde um simples que roda tudo localmente (`SequentialExecutor`) at√© executores distribu√≠dos que usam Celery ou Kubernetes para escalar horizontalmente.
4.  **Metastore (Banco de Metadados):** Um banco de dados (geralmente **PostgreSQL** ou **MySQL**) que armazena o estado de todas as tarefas, **DAGs**, conex√µes, vari√°veis, etc. √â o estado persistente do Airflow.


```mermaid
graph TD
    User[üë§ Airflow User]
    DAGFiles[üìÅ DAG files]
    PluginFolder[üêç Plugin folder<br/>& installed packages]
    Scheduler[üîÑ Parsing, Scheduling & Executing<br/>Scheduler]
    UI[üñ•Ô∏è UI<br/>API Server]
    MetadataDB[(üóÑÔ∏è Metadata DB)]
    
    User -->|install| PluginFolder
    User -->|author| DAGFiles
    User -->|operate| UI
    
    DAGFiles -->|read| Scheduler
    PluginFolder -->|install| Scheduler
    PluginFolder -->|install| UI
    
    Scheduler -.->|read/write| MetadataDB
    UI -.->|read/write| MetadataDB
    
    style MetadataDB fill:#4682b4,color:#fff
    style DAGFiles fill:#4074b8,color:#fff
    style PluginFolder fill:#4074b8,color:#fff
```
**Fonte**: Adaptado da documenta√ß√£o Oficial do Airflow

## Por que usar Airflow?

O Airflow se destaca por v√°rias raz√µes:

-   **Flexibilidade:** A abordagem *Workflows as Code* permite criar fluxos de trabalho complexos que seriam dif√≠ceis de definir em uma interface gr√°fica.
-   **Escalabilidade:** Com executores como **Celery** e **Kubernetes**, o **Airflow** pode gerenciar milhares de tarefas concorrentes.
-   **Ecossistema Extenso:** Uma comunidade significativa e um grande n√∫mero de *providers* (pacotes de integra√ß√£o) permitem que o **Airflow** se conecte a praticamente qualquer servi√ßo ou tecnologia que voc√™ possa imaginar (AWS, GCP, Azure, Databricks, Snowflake, etc.).
-   **Interface Rica:** A UI do **Airflow** √© poderosa para visualiza√ß√£o, monitoramento e depura√ß√£o de *workflows*.

## Quando n√£o usar Airflow?

O **Airflow** brilha em cen√°rios de processamento em lote (*batch*), ou seja, para tarefas que t√™m um come√ßo, meio e fim definidos.

Ele n√£o foi desenhado para ser um sistema de *streaming* ou para reagir a eventos em tempo real. Se o seu caso de uso envolve processar um fluxo cont√≠nuo de dados √† medida que eles chegam, utilize solu√ß√µes espec√≠ficas para *streaming*.

!!! info "Airflow em Streaming"
    No entanto, √© comum ver o **Airflow** trabalhando em conjunto com esses sistemas: o sistema de *streaming* captura e armazena os dados, e um **DAG** do **Airflow** √© agendado para, periodicamente (a cada hora, por exemplo), processar esses dados em lote.

Outro ponto importante √© a filosofia **Workflow as Code**. O **Airflow** pode n√£o ser a escolha ideal para quem prefere ferramentas puramente visuais, com interfaces *drag-and-drop* para criar fluxos de dados.

!!! info "Airflow e Workflow as Code"
    O **Airflow** fornece uma interface web seja excelente para monitoramento e gerenciamento, mas a cria√ß√£o e a manuten√ß√£o dos *workflows* s√£o feitas utilizando c√≥digo Python.

Avance para a pr√≥xima se√ß√£o para criar um **DAG** e ver esses conceitos em a√ß√£o!
